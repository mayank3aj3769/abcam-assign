{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb3a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# List of valid amino acids-> 'X' represents ambiguous data).\n",
    "AMINO_ACIDS = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', \n",
    "               'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', 'X']\n",
    "\n",
    "# AMINO_ACID_MAP: A dictionary that maps each amino acid to an index.\n",
    "AMINO_ACID_MAP = {char: idx for idx, char in enumerate(AMINO_ACIDS)} \n",
    "\n",
    "# ONE_HOT_X: A one-hot encoding for the letter 'X' \n",
    "ONE_HOT_X = np.eye(len(AMINO_ACIDS))[-1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a416e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceProcessor:\n",
    "    \"\"\"Class to handle sequence processing tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, file_path: str):\n",
    "        \"\"\"Initializes with the path to the CSV file.\"\"\"\n",
    "        self.file_path = file_path\n",
    "        self.data = None\n",
    "        self.processed_data = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Loads CSV file and rename columns.\"\"\"\n",
    "        self.data = pd.read_csv(self.file_path, header=None)\n",
    "        self.data.columns = ['identifier', 'sequence']\n",
    "\n",
    "    @staticmethod\n",
    "    def one_hot_encode_vectorized(sequence, max_length):\n",
    "        \"\"\" \n",
    "            1- Converts the sequence into one-hot encoded vectors for each amino acid.\n",
    "            2- Pads sequences that are shorter than the maximum sequence length with the one-hot encoding of 'X'.\n",
    "        \"\"\"\n",
    "        indices = [AMINO_ACID_MAP.get(char, len(AMINO_ACIDS) - 1) for char in sequence]\n",
    "        one_hot = np.eye(len(AMINO_ACIDS), dtype=int)[indices]\n",
    "        padded = np.vstack((one_hot, np.tile(ONE_HOT_X, (max_length - len(one_hot), 1))))[:max_length]\n",
    "        return padded.flatten()\n",
    "\n",
    "    @staticmethod\n",
    "    def letter_composition_vectorized(sequence):\n",
    "        \"\"\"\n",
    "            1- Computes the frequency distribution of amino acids in the sequence.\n",
    "            2- Normalizes the counts to obtain a vector that represents the composition of the sequence.\n",
    "        \"\"\"\n",
    "        counts = np.zeros(len(AMINO_ACIDS), dtype=float)\n",
    "        indices = [AMINO_ACID_MAP.get(char, len(AMINO_ACIDS) - 1) for char in sequence]\n",
    "        np.add.at(counts, indices, 1)\n",
    "        total = len(sequence)\n",
    "        return counts / total if total > 0 else counts\n",
    "    \n",
    "    def process_sequences(self):\n",
    "        \"\"\" \n",
    "            1- This function processes the entire DataFrame of sequences.\n",
    "            2- For each sequence, it applies the one_hot_encode_vectorized and letter_composition_vectorized functions.\n",
    "            3- The result is a new DataFrame containing the identifier, one-hot encoded vector, and letter composition vector for each sequence.\n",
    "        \"\"\"\n",
    "        max_length = max(self.data['sequence'].apply(len))\n",
    "        one_hot_vectors = self.data['sequence'].apply(lambda seq: self.one_hot_encode_vectorized(seq, max_length))\n",
    "        composition_vectors = self.data['sequence'].apply(self.letter_composition_vectorized)\n",
    "        self.processed_data = pd.DataFrame({\n",
    "            'identifier': self.data['identifier'],\n",
    "            'one_hot_vector': one_hot_vectors,\n",
    "            'composition_vector': composition_vectors\n",
    "        })\n",
    "        return self.processed_data\n",
    "    \n",
    "    def process_csv(self):\n",
    "        \"\"\"\n",
    "        Load a CSV file, rename columns, and process sequences using vectorized functions.\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            self.load_data()\n",
    "        \n",
    "        return self.process_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a38e064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  identifier                                     one_hot_vector  \\\n",
      "0         ID  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1          0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2          1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3          2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4          3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                  composition_vector  \n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "1  [0.10465116279069768, 0.023255813953488372, 0....  \n",
      "2  [0.11952191235059761, 0.0398406374501992, 0.05...  \n",
      "3  [0.06258596973865199, 0.0171939477303989, 0.04...  \n",
      "4  [0.0695742471443406, 0.017653167185877467, 0.0...  \n"
     ]
    }
   ],
   "source": [
    "# File path for the input CSV\n",
    "csv_file_path = \"uniprot_sequences.csv\"\n",
    "\n",
    "# Creating an instance of SequenceProcessor\n",
    "processor = SequenceProcessor(csv_file_path)\n",
    "\n",
    "# Loading and processing the data\n",
    "processor.load_data()\n",
    "processed_data = processor.process_sequences()\n",
    "\n",
    "# Displaying the processed data\n",
    "print(processed_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fc0c433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_letter_composition (__main__.TestSequenceProcessing.test_letter_composition)\n",
      "Verifies that the sum of the composition vector is approximately 1.0 for each sequence, ... ok\n",
      "test_one_hot_encoding (__main__.TestSequenceProcessing.test_one_hot_encoding)\n",
      "Verifies that the one-hot encoded vectors have the correct length (i.e., max_length * 21). ... ok\n",
      "test_process_csv (__main__.TestSequenceProcessing.test_process_csv)\n",
      "Assumes the presence of a CSV file and ensures the processed result contains the expected columns. ... ok\n",
      "test_process_sequences (__main__.TestSequenceProcessing.test_process_sequences)\n",
      "Ensures that the processed DataFrame contains the expected columns: ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 6.953s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import pandas as pd\n",
    "\n",
    "class TestSequenceProcessing(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        \"\"\"Prepares sample data for testing.\"\"\"\n",
    "        self.data = pd.DataFrame({\n",
    "            'identifier': ['protein_1', 'protein_2'],\n",
    "            'sequence': ['ACDEFGHIKLM', 'ACDX']\n",
    "        })\n",
    "        self.pr=SequenceProcessor('uniprot_sequences.csv')\n",
    "        self.processed_data = self.pr.process_csv() \n",
    "        \n",
    "    def test_one_hot_encoding(self):\n",
    "        \"\"\"Verifies that the one-hot encoded vectors have the correct length (i.e., max_length * 21).\"\"\"\n",
    "        encoded_1 = SequenceProcessor.one_hot_encode_vectorized('ACDEFGHIKLM', max_length=12)\n",
    "        encoded_2 = SequenceProcessor.one_hot_encode_vectorized('ACDX', max_length=12)\n",
    "        \n",
    "        # Checks if length of one-hot encoded vector is correct\n",
    "        self.assertEqual(len(encoded_1), 12 * 21)\n",
    "        self.assertEqual(len(encoded_2), 12 * 21)\n",
    "        \n",
    "    def test_letter_composition(self):\n",
    "        \"\"\"Verifies that the sum of the composition vector is approximately 1.0 for each sequence, \n",
    "           which confirms the vector has been normalized. \"\"\"\n",
    "        composition_1 = SequenceProcessor.letter_composition_vectorized('ACDEFGHIKLM')\n",
    "        composition_2 = SequenceProcessor.letter_composition_vectorized('ACDX')\n",
    "        \n",
    "        # Checks that the sum of composition vector is approximately 1.0\n",
    "        self.assertAlmostEqual(np.sum(composition_1), 1.0, places=1)\n",
    "        self.assertAlmostEqual(np.sum(composition_2), 1.0, places=1)\n",
    "    \n",
    "    def test_process_sequences(self):\n",
    "        \"\"\"Ensures that the processed DataFrame contains the expected columns: \n",
    "            'identifier', 'one_hot_vector', and 'composition_vector'.\"\"\"\n",
    "        processed_data=self.pr.process_sequences()\n",
    "        \n",
    "        # Checks if the processed data contains the correct columns\n",
    "        self.assertIn('identifier', processed_data.columns)\n",
    "        self.assertIn('one_hot_vector', processed_data.columns)\n",
    "        self.assertIn('composition_vector', processed_data.columns)\n",
    "        \n",
    "    def test_process_csv(self):\n",
    "        # Ensure the data contains the expected columns\n",
    "        self.assertIn('identifier', self.processed_data.columns)\n",
    "        self.assertIn('one_hot_vector', self.processed_data.columns)\n",
    "        self.assertIn('composition_vector', self.processed_data.columns)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    # Run the test suite\n",
    "    test_loader = unittest.TestLoader()\n",
    "    test_suite = test_loader.loadTestsFromTestCase(TestSequenceProcessing)\n",
    "    test_runner = unittest.TextTestRunner(verbosity=2)\n",
    "    test_runner.run(test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1acc8f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ccdfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae840812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env (GPU enabled)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
